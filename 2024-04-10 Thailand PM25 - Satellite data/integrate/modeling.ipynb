{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from zkyhaxpy import io_tools, gis_tools, pd_tools\n",
    "import rasterio\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import aqi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_predicted_pm25_root = r'../data/predicted_pm25_chiangmai'\n",
    "dir_predicted_pm25_daily = os.path.join(dir_predicted_pm25_root, 'daily')\n",
    "dir_predicted_pm25_monthly = os.path.join(dir_predicted_pm25_root, 'monthly')\n",
    "io_tools.create_folders(dir_predicted_pm25_daily, dir_predicted_pm25_monthly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aqi_color_codes = {\n",
    "        -9:\"Grey\",\n",
    "        0: \"Green\",\n",
    "        1: \"Yellow\",\n",
    "        2: \"Orange\",\n",
    "        3: \"Red\",\n",
    "        4: \"Purple\",\n",
    "        5: \"Maroon\"\n",
    "    }    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pm25_to_aqi_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pm25_to_aqi_level(pm25_concentration: float) -> int:\n",
    "    \"\"\"\n",
    "    Converts PM2.5 concentration to AQI class (as integer).\n",
    "\n",
    "    Args:\n",
    "        pm25_concentration (float): PM2.5 concentration in µg/m³.\n",
    "\n",
    "    Returns:\n",
    "        int: AQI level (0 to 5) based on EPA guidelines.\n",
    "    \"\"\"\n",
    "    aqi_value = aqi.to_aqi([(aqi.POLLUTANT_PM25, str(pm25_concentration))])\n",
    "    if aqi_value <= 50:\n",
    "        return 0  # Good\n",
    "    elif 50 < aqi_value <= 100:\n",
    "        return 1  # Moderate\n",
    "    elif 100 < aqi_value <= 150:\n",
    "        return 2  # Unhealthy for Sensitive Groups\n",
    "    elif 150 < aqi_value <= 200:\n",
    "        return 3  # Unhealthy\n",
    "    elif 200 < aqi_value <= 300:\n",
    "        return 4  # Very Unhealthy\n",
    "    else:\n",
    "        return 5  # Hazardous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aqi_level_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def aqi_level_to_color(aqi_class: int) -> str:\n",
    "    \"\"\"\n",
    "    Converts AQI level (as integer) to color code.\n",
    "\n",
    "    Args:\n",
    "        aqi_class (int): AQI level (0 to 5).\n",
    "\n",
    "    Returns:\n",
    "        str: Color code corresponding to the AQI level.\n",
    "    \"\"\"\n",
    "    color_codes = {\n",
    "        0: \"Green\",\n",
    "        1: \"Yellow\",\n",
    "        2: \"Orange\",\n",
    "        3: \"Red\",\n",
    "        4: \"Purple\",\n",
    "        5: \"Maroon\"\n",
    "    }\n",
    "    return color_codes.get(aqi_class, \"Unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chiangmai_grid = pd.read_parquet(r'../data/df_chiangmai_grid.parquet')\n",
    "\n",
    "lat_min = df_chiangmai_grid.lat.min()\n",
    "lat_max = df_chiangmai_grid.lat.max()\n",
    "lon_min = df_chiangmai_grid.lon.min()\n",
    "lon_max = df_chiangmai_grid.lon.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_aod055 = pd.read_csv(r'../data/df_extracted_aod055.csv')\n",
    "del(df_extracted_aod055['row'])\n",
    "del(df_extracted_aod055['col'])\n",
    "del(df_extracted_aod055['tile_id'])\n",
    "\n",
    "df_extracted_dem = pd.read_csv(r'../data/df_extracted_dem.csv')\n",
    "del(df_extracted_dem['row'])\n",
    "del(df_extracted_dem['col'])\n",
    "\n",
    "\n",
    "path_df_openaq = r'../data/df_openaq.parquet'\n",
    "if os.path.exists(path_df_openaq):\n",
    "    df_openaq = pd.read_parquet(path_df_openaq)\n",
    "    print(f'{path_df_openaq} has been loaded')\n",
    "else:\n",
    "    gdf_openaq = gpd.read_file('../data/gdf_openaq.gpkg')\n",
    "    print('gdf_openaq has been loaded.')\n",
    "    if gdf_openaq.index.name is None:\n",
    "        gdf_openaq = gdf_openaq.set_index('measurement_id')\n",
    "    \n",
    "    df_openaq = gdf_openaq.drop(columns=['geometry']).copy()\n",
    "    df_openaq.to_parquet(path_df_openaq)\n",
    "    print(f'{path_df_openaq} has been saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openaq = df_openaq[df_openaq['value'] != -999].copy()\n",
    "df_openaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_aod055 = df_extracted_aod055[df_extracted_aod055['aod_055'] >= 0].copy()\n",
    "df_extracted_aod055 = df_extracted_aod055.set_index('measurement_id')\n",
    "df_extracted_aod055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_dem = df_extracted_dem.copy()\n",
    "df_extracted_dem = df_extracted_dem.set_index('measurement_id')\n",
    "df_extracted_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_openaq.merge(df_extracted_aod055, how='inner', left_index=True, right_index=True).copy()\n",
    "df_joined = df_joined.merge(df_extracted_dem, how='inner', left_index=True, right_index=True).copy()\n",
    "df_joined = df_joined.rename(columns={'value':'pm25'})\n",
    "\n",
    "\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm25 = df_joined[(df_joined['lat'].between(lat_min, lat_max)) & (df_joined['long'].between(lon_min, lon_max))]\n",
    "df_pm25 = df_pm25.reindex(columns=['pm25', 'aod_055', 'dem', 'sensorType']).copy()\n",
    "df_pm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(df_pm25['pm25'], df_pm25['aod_055'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.scatter(df_pm25, x=\"aod_055\", y=f\"pm25\", color=\"sensorType\", title=f\"Scatterplot - OpenAQ's PM2.5 and MODIS' Aerosol Optical Depth (AOD) in Chiangmai (2021 - Present)\")\n",
    "fig.update_layout(\n",
    "    yaxis_title='PM2.5 (µg/m3)', \n",
    "    xaxis_title='AOD band 550 nm', \n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(r'./scatter-pm25-aod.html', include_plotlyjs=False, full_html=False, div_id=f'scatter-pm25-aod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_pm25, x='aod_055', y='pm25', hue='pm25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load your sample DataFrame (replace with your actual data)\n",
    "# Assuming your DataFrame is named 'df' and contains columns 'pm25', 'aod_055', and 'dem'\n",
    "# You can replace the sample data with your actual data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_pm25[['aod_055', ]]\n",
    "y = df_pm25['pm25']\n",
    "\n",
    "\n",
    "# Split data into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit OLS model\n",
    "X_train_ols = sm.add_constant(X_train)  # Add constant term\n",
    "ols_model = sm.OLS(y_train, X_train_ols).fit()\n",
    "\n",
    "# Get summary of OLS model\n",
    "print(ols_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add constant term to test data\n",
    "X_test_ols = sm.add_constant(X_test)\n",
    "\n",
    "# Predict pm25 values\n",
    "y_pred = ols_model.predict(X_test_ols)\n",
    "\n",
    "# Evaluate the model (optional)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict grid in Chiangmai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Chiangmai grid & DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_chiangmai_dem = pd.read_parquet(r'..\\data\\df_chiangmai_dem.parquet')\n",
    "df_chiangmai_joined = df_chiangmai_grid.merge(df_chiangmai_dem, how='inner', left_index=True, right_index=True)\n",
    "df_chiangmai_joined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_chiangmai_aod_daily = r'../data/chiangmai_aod_daily'\n",
    "list_file_aod_daily = io_tools.get_list_files(dir_chiangmai_aod_daily, '.parquet$')\n",
    "pbar_aod_daily = tqdm(list_file_aod_daily)\n",
    "# rerun = input('Rerun? (Y/N)')\n",
    "rerun = 'Y'\n",
    "if rerun.upper()=='Y':\n",
    "    rerun_f = True\n",
    "else:\n",
    "    rerun_f = False\n",
    "\n",
    "for path_aod_daily in pbar_aod_daily:\n",
    "    \n",
    "    year_month = os.path.basename(path_aod_daily)[23:30]\n",
    "    tile_id = os.path.basename(path_aod_daily)[31:37]\n",
    "    \n",
    "    path_out_daily = os.path.join(dir_predicted_pm25_daily, f'df_predict_pm25-{year_month}-{tile_id}.parquet')\n",
    "\n",
    "    if os.path.exists(path_out_daily):\n",
    "        if not rerun_f:\n",
    "            continue\n",
    "\n",
    "    df_aod_daily = pd.read_parquet(path_aod_daily)\n",
    "    del(df_aod_daily['year_month'])\n",
    "    del(df_aod_daily['tile_id'])\n",
    "    df_predict_pm25 = pd.melt(df_aod_daily, ignore_index=False, )\n",
    "    df_predict_pm25 = df_predict_pm25.dropna().copy()\n",
    "    df_predict_pm25 = df_predict_pm25.rename(columns={'variable':'date', 'value':'aod_055'})\n",
    "    df_predict_pm25 = df_chiangmai_dem.merge(df_predict_pm25, how='inner', left_index=True, right_index=True) \n",
    "    X_predict = df_predict_pm25[['aod_055', 'dem']]\n",
    "\n",
    "\n",
    "    #OLS\n",
    "    X_predict = df_predict_pm25[['aod_055',]]\n",
    "    X_predict_ols = sm.add_constant(X_predict)\n",
    "    y_pred = ols_model.predict(X_predict_ols)\n",
    "\n",
    "    assert(len(y_pred)) == (len(df_predict_pm25))\n",
    "    df_predict_pm25['pm25_pred'] = y_pred\n",
    "\n",
    "    df_predict_pm25 = df_predict_pm25.merge(df_chiangmai_grid, how='left', left_index=True, right_index=True).copy()\n",
    "    \n",
    "    df_predict_pm25.to_parquet(path_out_daily)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save into monthly image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_files_predicted_daily = io_tools.get_list_files(dir_predicted_pm25_daily, 'df_predict_pm25-.*.parquet', return_df=True)\n",
    "df_list_files_predicted_daily['year_month'] = df_list_files_predicted_daily['file_nm'].str.slice(16,23)\n",
    "df_list_files_predicted_daily['tile_id'] = df_list_files_predicted_daily['file_nm'].str.slice(24,30)\n",
    "\n",
    "\n",
    "#Aggregate data in each month by calculating median for each grid\n",
    "list_df_predict_pm25_monthly_median = []\n",
    "list_df_predict_pm25_monthly_mean = []\n",
    "print('Aggregating into monthly mean & median')\n",
    "for year_month, df_list_files_curr in tqdm(df_list_files_predicted_daily.groupby('year_month')):    \n",
    "    df_predict_pm25 = pd.concat([pd.read_parquet(file_path) for file_path in df_list_files_curr['file_path']])    \n",
    "    df_predict_pm25_monthly_median = df_predict_pm25.groupby(['lat', 'lon', 'dem']).agg(year_month=('pm25_pred', 'median')).rename(columns={'year_month':year_month})\n",
    "    df_predict_pm25_monthly_mean = df_predict_pm25.groupby(['lat', 'lon', 'dem']).agg(year_month=('pm25_pred', 'mean')).rename(columns={'year_month':year_month})\n",
    "    list_df_predict_pm25_monthly_median.append(df_predict_pm25_monthly_median)\n",
    "    list_df_predict_pm25_monthly_mean.append(df_predict_pm25_monthly_mean)\n",
    "df_predict_pm25_monthly_median = pd.concat(list_df_predict_pm25_monthly_median, axis=1)  \n",
    "df_predict_pm25_monthly_mean = pd.concat(list_df_predict_pm25_monthly_mean, axis=1)  \n",
    "\n",
    "#Fill missing value from cloudy effect by Interpolation\n",
    "print('Interpolating monthly median...')\n",
    "df_predict_pm25_monthly_median = df_predict_pm25_monthly_median.interpolate(axis=1).copy()  \n",
    "print('Interpolating monthly mean...')\n",
    "df_predict_pm25_monthly_mean = df_predict_pm25_monthly_mean.interpolate(axis=1).copy()  \n",
    "\n",
    "#Save \n",
    "print('Saving...')\n",
    "df_predict_pm25_monthly_median.to_parquet(r'../data/df_predict_pm25_monthly_median.parquet')\n",
    "df_predict_pm25_monthly_mean.to_parquet(r'../data/df_predict_pm25_monthly_mean.parquet')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
